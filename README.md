# AI Mixture of Experts for Cybersecurity Requirements (MoE-CySec)

## 1. Project Goal and Research Motivation

This project explores the implementation of a **Mixture of Experts (MoE)** architecture using small, efficient Large Language Models (LLMs) to address complex cybersecurity challenges. The primary goal is to move beyond monolithic AI systems and evaluate how a distributed system of specialized AI agents can generate high-quality, actionable, and context-aware security requirements.

The core of this research is not just to build a functional MoE system, but to establish a framework for **evaluating the quality and performance of different LLMs** when tasked with specialized roles within this architecture. We aim to answer critical questions such as:
*   How effectively can a small LLM (e.g., ~0.5-8B parameters) function as an intelligent "router," correctly dispatching tasks to the appropriate expert?
*   How does a model's performance change when its scope is narrowed by a highly specific system prompt (i.e., acting as a domain expert)?
*   What are the failure modes of small models in this architecture, and how can we build a robust system around them?

This repository serves as a practical testbed for systematically evaluating LLMs across several key performance vectors.

## 2. Evaluation Framework

The MoE system is designed as an evaluation framework to measure the capabilities of different language models on several critical axes:

### a) Routing Accuracy and Instruction Following
The first point of evaluation is the AI Router. We assess its ability to correctly parse a user's natural language query and map it to the most suitable expert. This measures:
*   **Semantic Understanding:** Can the router comprehend the user's intent beyond simple keywords?
*   **Instruction Following:** How reliably does the model adhere to the strict output format (e.g., a clean JSON object) specified in its system prompt? This is a crucial test of a model's "alignment."
*   **Robustness:** How does the router behave with ambiguous or out-of-scope queries?

### b) Quality of Expert Response
Once a task is routed, we evaluate the quality of the response generated by the chosen expert model. This is the core of the evaluation, measuring:
*   **Factual Accuracy and Relevance:** Is the generated information correct and directly relevant to the query? (This will be enhanced by integrating Retrieval-Augmented Generation (RAG) in future work).
*   **Persona Adherence:** How well does the model adopt the persona defined in its system prompt (e.g., a "Threat Analyst" vs. a "Controls Engineer")? We measure this by analyzing the tone, terminology, and focus of the response.
*   **Actionability and Clarity:** Is the output useful in a real-world scenario? For a `controls_engineer` expert, this means generating clear, specific, and actionable functional requirements, not vague advice.

### c) System-Level Performance and Efficiency
We also analyze the system as a whole to understand its practical viability:
*   **Latency:** What is the end-to-end time from query to response? This includes the inference time of both the router and the expert.
*   **Computational Cost:** By using small, local models (via Ollama), we can profile memory (VRAM) and resource usage, providing a baseline for the cost-effectiveness of this approach compared to using large, proprietary APIs.
*   **Error Resilience:** The framework includes fallback mechanisms and robust parsing. We log every time these fallbacks are triggered, providing valuable data on the system's overall reliability.

## 3. How It Works: The MoE Architecture

The system is composed of two main components:

1.  **AI Router (`LLMRouter`):** A lightweight LLM (e.g., `qwen2:0.5b`) is tasked with a single, focused job: classification. It reads the user's query and the descriptions of available experts, then outputs the name of the best expert for the job.
2.  **Specialized Experts (`Expert`):** A pool of LLM agents (e.g., using `qwen2:1.5b`), where each is configured with a unique system prompt. This prompt "specializes" the general-purpose model into a domain-specific expert, such as:
    *   `compliance_expert`: Knows about GDPR, DORA, ISO 27001.
    *   `threat_analyst`: Thinks like an attacker, using frameworks like MITRE ATT&CK.
    *   `controls_engineer`: Thinks in solutions, suggesting practical security controls.

The entire process is logged to `moe_system_log.txt`, capturing the router's decision, the final generated response, and a comparison against a pre-defined "gold-standard" answer to systematically evaluate performance over time.

This project aims to provide concrete, empirical insights into the strengths and weaknesses of different small language models, paving the way for more robust, efficient, and specialized AI systems in the cybersecurity domain.
